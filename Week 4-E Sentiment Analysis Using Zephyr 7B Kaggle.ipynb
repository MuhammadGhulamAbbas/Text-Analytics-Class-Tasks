{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7498620,"sourceType":"datasetVersion","datasetId":4366455}],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\nfrom transformers.generation import GenerationConfig\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport textwrap\nimport torch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-28T13:55:11.700602Z","iopub.execute_input":"2024-01-28T13:55:11.700975Z","iopub.status.idle":"2024-01-28T13:55:14.640659Z","shell.execute_reply.started":"2024-01-28T13:55:11.700944Z","shell.execute_reply":"2024-01-28T13:55:14.639849Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# load the dataset\nwith open('/kaggle/input/imdb-corpus/corpus.txt','r',encoding=\"utf8\") as f:\n    document = f.readlines()\nf.close()\n\nlabels, texts = [], []\nfor line in document:\n    content = line.split()\n    label = content[0]\n    labels.append(label[-1])\n    texts.append(\" \".join(content[1:]))\n\nprint(len(labels), len(texts))","metadata":{"execution":{"iopub.status.busy":"2024-01-28T13:55:17.764751Z","iopub.execute_input":"2024-01-28T13:55:17.765634Z","iopub.status.idle":"2024-01-28T13:55:17.950071Z","shell.execute_reply.started":"2024-01-28T13:55:17.765600Z","shell.execute_reply":"2024-01-28T13:55:17.949202Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"10000 10000\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train2, X_test2, y_train, y_test  = train_test_split(texts, labels, train_size=0.75,random_state=1234)","metadata":{"execution":{"iopub.status.busy":"2024-01-28T13:55:21.436322Z","iopub.execute_input":"2024-01-28T13:55:21.437070Z","iopub.status.idle":"2024-01-28T13:55:22.085100Z","shell.execute_reply.started":"2024-01-28T13:55:21.437038Z","shell.execute_reply":"2024-01-28T13:55:22.084306Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline\n","metadata":{"execution":{"iopub.status.busy":"2024-01-28T13:55:24.120206Z","iopub.execute_input":"2024-01-28T13:55:24.121084Z","iopub.status.idle":"2024-01-28T13:55:27.765684Z","shell.execute_reply.started":"2024-01-28T13:55:24.121050Z","shell.execute_reply":"2024-01-28T13:55:27.764870Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"model_path = \"HuggingFaceH4/zephyr-7b-beta\" \ntokenizer = AutoTokenizer.from_pretrained(model_path)\npipe = pipeline(\"text-generation\", model=model_path, torch_dtype=torch.bfloat16, device_map=\"auto\")","metadata":{"execution":{"iopub.status.busy":"2024-01-28T13:55:32.013145Z","iopub.execute_input":"2024-01-28T13:55:32.013955Z","iopub.status.idle":"2024-01-28T13:55:43.440475Z","shell.execute_reply.started":"2024-01-28T13:55:32.013920Z","shell.execute_reply":"2024-01-28T13:55:43.439479Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bf1ad618ef0460a97df024331f95c1a"}},"metadata":{}}]},{"cell_type":"code","source":"def get_completion(prompt):\n    messages = [{\n        \"role\": \"user\", \n        \"content\": prompt }]\n    prompt2 = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    outputs = pipe(prompt2, max_new_tokens=400, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)\n    return outputs[0][\"generated_text\"]","metadata":{"execution":{"iopub.status.busy":"2024-01-28T13:56:08.324910Z","iopub.execute_input":"2024-01-28T13:56:08.325779Z","iopub.status.idle":"2024-01-28T13:56:08.331125Z","shell.execute_reply.started":"2024-01-28T13:56:08.325742Z","shell.execute_reply":"2024-01-28T13:56:08.330178Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"zephyr_pred = []\nfor i, s in enumerate(X_test2):\n    if (i % 100) == 0:\n        print(i)\n    text = s\n    prompt = f\"\"\"\n    What is the sentiment of the following text, which is delimited with triple backticks?\n\n    Give your answer as a single word, either \"positive\" or \"negative\".\n    Review text: '''{text}'''\n    \"\"\"\n    response = get_completion(prompt)\n    zephyr_pred.append(response)","metadata":{"execution":{"iopub.status.busy":"2024-01-28T13:56:11.786001Z","iopub.execute_input":"2024-01-28T13:56:11.786353Z","iopub.status.idle":"2024-01-28T17:04:23.721055Z","shell.execute_reply.started":"2024-01-28T13:56:11.786327Z","shell.execute_reply":"2024-01-28T17:04:23.719978Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"0\n100\n200\n300\n400\n500\n600\n700\n800\n900\n1000\n1100\n1200\n1300\n1400\n1500\n1600\n1700\n1800\n1900\n2000\n2100\n2200\n2300\n2400\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2024-01-28T17:13:43.383548Z","iopub.execute_input":"2024-01-28T17:13:43.384860Z","iopub.status.idle":"2024-01-28T17:13:43.388919Z","shell.execute_reply.started":"2024-01-28T17:13:43.384822Z","shell.execute_reply":"2024-01-28T17:13:43.387961Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"zephyr_pred[0]","metadata":{"execution":{"iopub.status.busy":"2024-01-28T17:14:14.739458Z","iopub.execute_input":"2024-01-28T17:14:14.739857Z","iopub.status.idle":"2024-01-28T17:14:14.745762Z","shell.execute_reply.started":"2024-01-28T17:14:14.739825Z","shell.execute_reply":"2024-01-28T17:14:14.744836Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"'<|user|>\\n\\n    What is the sentiment of the following text, which is delimited with triple backticks?\\n\\n    Give your answer as a single word, either \"positive\" or \"negative\".\\n    Review text: \\'\\'\\'Poly tape: Does a great job highly visible. Works well with the different fencers that I use in the different pastures. Last a long time. Can\\'t beat it for the price.\\'\\'\\'\\n    </s>\\n<|assistant|>\\nThe sentiment of the review text delimited with triple backticks is \"positive\". Keywords such as \"great\", \"highly visible\", \"works well\", and \"lasts a long time\" indicate a favorable opinion of the product. The reviewer also mentions that the product is \"can\\'t beat it for the price\", implying that it is an excellent value. Overall, the sentiment is positive.'"},"metadata":{}}]},{"cell_type":"code","source":"sentiments = []\nfor zp in zephyr_pred:    \n    response = zp\n    abc = response.split('<|assistant|>')\n    s = abc[1]\n    if 'positive' in s.lower():\n        sentiments.append('2')\n    else:\n        sentiments.append('1')","metadata":{"execution":{"iopub.status.busy":"2024-01-28T17:24:57.863466Z","iopub.execute_input":"2024-01-28T17:24:57.864557Z","iopub.status.idle":"2024-01-28T17:24:57.874426Z","shell.execute_reply.started":"2024-01-28T17:24:57.864499Z","shell.execute_reply":"2024-01-28T17:24:57.873568Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"sentiments[0:10]\n  ","metadata":{"execution":{"iopub.status.busy":"2024-01-28T17:25:04.465404Z","iopub.execute_input":"2024-01-28T17:25:04.466326Z","iopub.status.idle":"2024-01-28T17:25:04.472057Z","shell.execute_reply.started":"2024-01-28T17:25:04.466291Z","shell.execute_reply":"2024-01-28T17:25:04.471200Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"['2', '1', '2', '1', '2', '2', '1', '2', '1', '1']"},"metadata":{}}]},{"cell_type":"code","source":"accuracy_score(y_test, sentiments)","metadata":{"execution":{"iopub.status.busy":"2024-01-28T17:25:41.376355Z","iopub.execute_input":"2024-01-28T17:25:41.377156Z","iopub.status.idle":"2024-01-28T17:25:41.389826Z","shell.execute_reply.started":"2024-01-28T17:25:41.377120Z","shell.execute_reply":"2024-01-28T17:25:41.388918Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"0.9224"},"metadata":{}}]}]}