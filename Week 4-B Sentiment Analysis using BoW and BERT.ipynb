{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/sahaider/AppData/Local/Programs/Microsoft VS Code\n",
      "/mnt/d/Sajjad/08-2023/Python Code/Text Analytics Fall 2024\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "#change working directory to the location of the data file\n",
    "os.chdir('/mnt/d/Sajjad/08-2023/Python Code/Text Analytics Fall 2024/')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"it is nice weather \", \"it is cold \", \"it is not very cold \", \"not nice \", \"very cold \", \"cold \", \"very nice weather \", \"it is not nice cold at all\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"it is not nice cold at all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using PLM (bert-finetune-sst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label     score\n",
       "0  NEGATIVE  0.999766"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"text-classification\")\n",
    "outputs = classifier(text)\n",
    "pd.DataFrame(outputs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in sentences:\n",
    "    outputs = classifier(s)\n",
    "    print(s, outputs[0]['label'], outputs[0]['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers.generation import GenerationConfig\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Try importing flash-attention for faster inference...\n",
      "Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm\n"
     ]
    }
   ],
   "source": [
    "# Note: The default behavior now has injection attack prevention off.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen-1_8B-Chat\", trust_remote_code=True)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"Qwen/Qwen-1_8B-Chat-Int4\", #\"Qwen/Qwen-7B-Chat-Int4\",\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ").eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model footprint: 622.43M\n",
      "model memory: 2489.72MB\n"
     ]
    }
   ],
   "source": [
    "#print model footprint\n",
    "print(f\"model footprint: {model.num_parameters() / 1e6:.2f}M\")\n",
    "#print memory taken by the model\n",
    "print(f\"model memory: {model.num_parameters() * 4 / 1e6:.2f}MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solving class example using Qwen LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The last sentence in the given examples is:  <sentiment>: not nice  <sentiment>:\n",
      "cold  <sentiment>: very cold  <sentiment>: negative   These sentences express\n",
      "different sentiments related to the weather. The first sentence has a positive\n",
      "sentiment as \"nice\" is used, while the second sentence expresses a negative\n",
      "sentiment with words like \"cold\", \"not nice\", and \"very cold\". The third\n",
      "sentence shows that there's a mix of positive and negative sentiments as \"not\n",
      "nice\" and \"cold\" are mentioned together. The fourth sentence indicates that the\n",
      "weather is not pleasant at all with words like \"nice\" and \"cold\". The fifth\n",
      "sentence also has a mixed sentiment, with words like \"not nice\" and \"very cold\".\n",
      "Overall, the last sentence can be classified as \"negative\" because it contains\n",
      "negative sentiments such as \"cold\" and \"very cold.\"\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Classify the last sentence using the following examples.\n",
    "\n",
    "<sentence>: it is nice weather \n",
    "<sentiment>: positive\n",
    "<sentence>: it is cold \n",
    "<sentiment>: negative\n",
    "<sentence>: it is not very cold \n",
    "<sentiment>: positive\n",
    "<sentence>: not nice \n",
    "<sentiment>: negative\n",
    "<sentence>: very cold \n",
    "<sentiment>: negative\n",
    "<sentence>: cold \n",
    "<sentiment>: negative\n",
    "<sentence>: very nice weather \n",
    "<sentiment>: positive\n",
    "<sentence>: it is not nice cold at all\n",
    "\n",
    "\"\"\"\n",
    "response, history = model.chat(tokenizer, prompt, history=None)\n",
    "print(textwrap.fill(response, width=80))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Qwen to evaluate all the 8 comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : it is nice weather \n",
      "The sentiment of the given text is positive. The word \"nice\" has a positive\n",
      "connotation and suggests that the person who wrote it is enjoying the weather.\n",
      "Probability: 100% (since the sentiment of the text is clearly positive)\n",
      "----------------------------------\n",
      "1 : it is cold \n",
      "The sentiment of the given text is negative.   Probability: The sentiment\n",
      "analysis model may have been trained on limited data and might not be able to\n",
      "accurately determine the sentiment of this text. Therefore, the probability\n",
      "cannot be provided without more context and information about the training data\n",
      "used for the sentiment analysis model.\n",
      "----------------------------------\n",
      "2 : it is not very cold \n",
      "The sentiment of the given text is negative. The words \"not very cold\" suggest\n",
      "that the temperature is chilly, and the overall tone is negative.\n",
      "----------------------------------\n",
      "3 : not nice \n",
      "The sentiment of the text can be classified as negative because the words \"not\n",
      "nice\" indicate a negative attitude or opinion towards something.  Based on this\n",
      "analysis, the sentiment of the text is likely to be \"negative\". The word \"not\"\n",
      "has a negative connotation and the phrase \"nice\" is not necessarily positive.\n",
      "Therefore, the probability of my answer being negative would be 100%.\n",
      "----------------------------------\n",
      "4 : very cold \n",
      "Based on the given text, it can be inferred that the sentiment expressed is\n",
      "negative. The phrase \"very cold\" conveys a negative sentiment as it implies a\n",
      "harsh and unpleasant temperature.  The probability of this answer is subjective\n",
      "and depends on individual interpretation of the text. However, based solely on\n",
      "the context provided, it can be concluded that the sentiment expressed is\n",
      "negative.\n",
      "----------------------------------\n",
      "5 : cold \n",
      "The sentiment of the text appears to be negative. The word \"cold\" generally has\n",
      "a negative connotation and suggests something unpleasant or unappealing.\n",
      "----------------------------------\n",
      "6 : very nice weather \n",
      "Based on the given text, it appears to be expressing positive sentiment as it\n",
      "contains words like \"nice\" and does not contain any negative phrases or\n",
      "expressions. Therefore, I would assign a sentiment score of \"positive\" to this\n",
      "text. The probability of an accurate prediction depends on various factors such\n",
      "as the language used, context, and domain expertise. However, in general, a\n",
      "sentiment analysis model trained on a large dataset that covers a wide range of\n",
      "contexts and industries can make reasonable predictions for this specific\n",
      "example.\n",
      "----------------------------------\n",
      "7 : it is not nice cold at all\n",
      "Based on the given text, it appears to be expressing a negative sentiment. The\n",
      "phrase \"not nice\" indicates that the weather is unpleasant and suggests a sense\n",
      "of dissatisfaction or disappointment. Therefore, my answer would be \"negative\",\n",
      "and the probability of this answer being correct could vary depending on various\n",
      "factors such as the context in which the text was written and the individual\n",
      "reader's subjective experience. However, based solely on the information\n",
      "provided, I would likely lean towards a negative sentiment.\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, s in enumerate(sentences):\n",
    "    text = s\n",
    "    print(i, \":\", text)\n",
    "    prompt = f\"\"\"\n",
    "    What is the sentiment of the following text, which is delimited with triple backticks?\n",
    "\n",
    "    Give your answer as either \"positive\" or \"negative\". If possible, also share the probability of your answer.\n",
    "    Review text: '''{text}'''\n",
    "    \"\"\"\n",
    "    response, history = model.chat(tokenizer, prompt, history=None)\n",
    "    print(textwrap.fill(response, width=80))\n",
    "    print(\"----------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 10000\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "with open('corpus.txt','r',encoding=\"utf8\") as f:\n",
    "    document = f.readlines()\n",
    "f.close()\n",
    "\n",
    "labels, texts = [], []\n",
    "for line in document:\n",
    "    content = line.split()\n",
    "    label = content[0]\n",
    "    labels.append(label[-1])\n",
    "    texts.append(\" \".join(content[1:]))\n",
    "\n",
    "print(len(labels), len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^',\n",
       " \"The best soundtrack ever to anything.: I'm reading a lot of reviews saying that this is the best 'game soundtrack' and I figured that I'd write a review to disagree a bit. This in my opinino is Yasunori Mitsuda's ultimate masterpiece. The music is timeless and I'm been listening to it for years now and its beauty simply refuses to fade.The price tag on this is pretty staggering I must say, but if you are going to buy any cd for this much money, this is the only one that I feel would be worth every penny.\",\n",
       " 'Amazing!: This soundtrack is my favorite music of all time, hands down. The intense sadness of \"Prisoners of Fate\" (which means all the more if you\\'ve played the game) and the hope in \"A Distant Promise\" and \"Girl who Stole the Star\" have been an important inspiration to me personally throughout my teen years. The higher energy tracks like \"Chrono Cross ~ Time\\'s Scar~\", \"Time of the Dreamwatch\", and \"Chronomantique\" (indefinably remeniscent of Chrono Trigger) are all absolutely superb as well.This soundtrack is amazing music, probably the best of this composer\\'s work (I haven\\'t heard the Xenogears soundtrack, so I can\\'t say for sure), and even if you\\'ve never played the game, it would be worth twice the price to buy it.I wish I could give it 6 stars.',\n",
       " \"Excellent Soundtrack: I truly like this soundtrack and I enjoy video game music. I have played this game and most of the music on here I enjoy and it's truly relaxing and peaceful.On disk one. my favorites are Scars Of Time, Between Life and Death, Forest Of Illusion, Fortress of Ancient Dragons, Lost Fragment, and Drowned Valley.Disk Two: The Draggons, Galdorb - Home, Chronomantique, Prisoners of Fate, Gale, and my girlfriend likes ZelbessDisk Three: The best of the three. Garden Of God, Chronopolis, Fates, Jellyfish sea, Burning Orphange, Dragon's Prayer, Tower Of Stars, Dragon God, and Radical Dreamers - Unstealable Jewel.Overall, this is a excellent soundtrack and should be brought by those that like video game music.Xander Cross\",\n",
       " \"Remember, Pull Your Jaw Off The Floor After Hearing it: If you've played the game, you know how divine the music is! Every single song tells a story of the game, it's that good! The greatest songs are without a doubt, Chrono Cross: Time's Scar, Magical Dreamers: The Wind, The Stars, and the Sea and Radical Dreamers: Unstolen Jewel. (Translation varies) This music is perfect if you ask me, the best it can be. Yasunori Mitsuda just poured his heart on and wrote it down on paper.\"]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2', '2', '2', '2', '2', '2', '1', '2', '2', '2']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing BoW using CountVectorizer and TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 31627)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_vectorizer = CountVectorizer()\n",
    "features = cnt_vectorizer.fit_transform(texts)\n",
    "features_nd = features.toarray()\n",
    "features_nd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test  = train_test_split(features_nd, labels, train_size=0.75,random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.846"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = MultinomialNB()\n",
    "clf1.fit(X_train, y_train)\n",
    "y_pred = clf1.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using countvectorize with trigram and remove stop words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7156"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_vectorizer = CountVectorizer(ngram_range=(1, 2),max_features=100)\n",
    "features = cnt_vectorizer.fit_transform(texts)\n",
    "features_nd = features.toarray()\n",
    "print(features_nd.shape)\n",
    "X_train, X_test, y_train, y_test  = train_test_split(features_nd, labels, train_size=0.75,random_state=1234)\n",
    "clf1 = MultinomialNB()\n",
    "clf1.fit(X_train, y_train)\n",
    "y_pred = clf1.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 200)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7384"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_vectorizer = CountVectorizer(ngram_range=(1, 2),max_features=200)\n",
    "features = cnt_vectorizer.fit_transform(texts)\n",
    "features_nd = features.toarray()\n",
    "print(features_nd.shape)\n",
    "X_train, X_test, y_train, y_test  = train_test_split(features_nd, labels, train_size=0.75,random_state=1234)\n",
    "clf1 = MultinomialNB()\n",
    "clf1.fit(X_train, y_train)\n",
    "y_pred = clf1.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 500)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8024"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_vectorizer = CountVectorizer(ngram_range=(1, 2),max_features=500)\n",
    "features = cnt_vectorizer.fit_transform(texts)\n",
    "features_nd = features.toarray()\n",
    "print(features_nd.shape)\n",
    "X_train, X_test, y_train, y_test  = train_test_split(features_nd, labels, train_size=0.75,random_state=1234)\n",
    "clf1 = MultinomialNB()\n",
    "clf1.fit(X_train, y_train)\n",
    "y_pred = clf1.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8264"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_vectorizer = CountVectorizer(ngram_range=(1, 2),max_features=2000)\n",
    "features = cnt_vectorizer.fit_transform(texts)\n",
    "features_nd = features.toarray()\n",
    "print(features_nd.shape)\n",
    "X_train, X_test, y_train, y_test  = train_test_split(features_nd, labels, train_size=0.75,random_state=1234)\n",
    "clf1 = MultinomialNB()\n",
    "clf1.fit(X_train, y_train)\n",
    "y_pred = clf1.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8228"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_vectorizer = CountVectorizer(ngram_range=(1, 5),max_features=2000)\n",
    "features = cnt_vectorizer.fit_transform(texts)\n",
    "features_nd = features.toarray()\n",
    "print(features_nd.shape)\n",
    "X_train, X_test, y_train, y_test  = train_test_split(features_nd, labels, train_size=0.75,random_state=1234)\n",
    "clf1 = MultinomialNB()\n",
    "clf1.fit(X_train, y_train)\n",
    "y_pred = clf1.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 5000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8432"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_vectorizer = CountVectorizer(ngram_range=(1, 3),max_features=5000)\n",
    "features = cnt_vectorizer.fit_transform(texts)\n",
    "features_nd = features.toarray()\n",
    "print(features_nd.shape)\n",
    "X_train, X_test, y_train, y_test  = train_test_split(features_nd, labels, train_size=0.75,random_state=1234)\n",
    "clf1 = MultinomialNB()\n",
    "clf1.fit(X_train, y_train)\n",
    "y_pred = clf1.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 31627)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.838"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()#(ngram_range=(1, 3),max_features=5000)\n",
    "features = tfidf_vectorizer.fit_transform(texts)\n",
    "features_nd = features.toarray()\n",
    "print(features_nd.shape)\n",
    "X_train, X_test, y_train, y_test  = train_test_split(features_nd, labels, train_size=0.75,random_state=1234)\n",
    "clf1 = MultinomialNB()\n",
    "clf1.fit(X_train, y_train)\n",
    "y_pred = clf1.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 5000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8456"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 3),max_features=5000)\n",
    "features = tfidf_vectorizer.fit_transform(texts)\n",
    "features_nd = features.toarray()\n",
    "print(features_nd.shape)\n",
    "X_train, X_test, y_train, y_test  = train_test_split(features_nd, labels, train_size=0.75,random_state=1234)\n",
    "clf1 = MultinomialNB()\n",
    "clf1.fit(X_train, y_train)\n",
    "y_pred = clf1.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8336"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = RandomForestClassifier()\n",
    "clf1.fit(X_train, y_train)\n",
    "y_pred = clf1.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7396"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = KNeighborsClassifier()\n",
    "clf1.fit(X_train, y_train)\n",
    "y_pred = clf1.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train, y_test  = train_test_split(texts, labels, train_size=0.75,random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating all 2500 test records using PLM (bert-finetuned-sst)\n",
    "\n",
    "This may take upto 2-3 minutes on your local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_pred = []\n",
    "for s in X_test2:\n",
    "    outputs = classifier(s)\n",
    "    bert_pred.append(outputs[0]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9016"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#map 'Positive' to 2 and 'Negative' to 1 in bert_pred list \n",
    "bert_pred2 = []\n",
    "for s in bert_pred:\n",
    "    if s == 'POSITIVE':\n",
    "        bert_pred2.append('2')\n",
    "    else:\n",
    "        bert_pred2.append('1')\n",
    "accuracy_score(y_test, bert_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take top 100 records from X_test2\n",
    "X_test2a = X_test[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qwen and Zephyr can't be done on local machines (specially laptops) and should be done on Cloud"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
